// Copyright 2025 Buf Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by buf.build/go/hyperpb/internal/tools/hyperstencil. DO NOT EDIT.

package thunks

import (
	"buf.build/go/hyperpb/internal/arena/slice"
	"buf.build/go/hyperpb/internal/debug"
	"buf.build/go/hyperpb/internal/swiss"
	"buf.build/go/hyperpb/internal/tdp"
	"buf.build/go/hyperpb/internal/tdp/dynamic"
	"buf.build/go/hyperpb/internal/tdp/repeated"
	"buf.build/go/hyperpb/internal/tdp/vm"
	"buf.build/go/hyperpb/internal/xunsafe"
	"buf.build/go/hyperpb/internal/xunsafe/layout"
	"buf.build/go/hyperpb/internal/zigzag"
	"google.golang.org/protobuf/encoding/protowire"
	"math/bits"
	"unsafe"
)

func parseMapV32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, varint32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi varint32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, varint64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi varint64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, zigzag32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi zigzag32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, zigzag64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi zigzag64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint32Item, bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, varint32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi varint32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, varint64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi varint64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, zigzag32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi zigzag32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, zigzag64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi zigzag64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varint64Item, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, varint32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi varint32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, varint64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi varint64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, zigzag32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi zigzag32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, zigzag64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi zigzag64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag32Item, bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, varint32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi varint32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, varint64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi varint64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, zigzag32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi zigzag32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, zigzag64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi zigzag64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzag64Item, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, varint32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi varint32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, varint64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi varint64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, zigzag32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi zigzag32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, zigzag64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi zigzag64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, varint32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi varint32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, varint64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi varint64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, zigzag32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi zigzag32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, zigzag64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi zigzag64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, varint32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi varint32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, varint64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi varint64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, zigzag32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi zigzag32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, zigzag64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi zigzag64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSx2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, varint32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi varint32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, varint64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi varint64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, zigzag32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi zigzag32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, zigzag64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi zigzag64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBx2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, varint32Item, uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi varint32Item
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, varint64Item, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi varint64Item
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, zigzag32Item, uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi zigzag32Item
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, zigzag64Item, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi zigzag64Item
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, fixed32Item, uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi fixed32Item
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint32](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, fixed64Item, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi fixed64Item
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, boolItem, uint8, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi boolItem
	var k uint8
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint8]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint8](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU8(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint8](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint8]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU8(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, stringItem, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi stringItem
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, bytesItem, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi bytesItem
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, xunsafe.Bytes(&k),
				v, xunsafe.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, uint64](cap)
		m = xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}

func parseMapV32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[varint32Item, uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint32Item
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, V](cap)
		m = xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapV64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[varint64Item, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varint64Item
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, V](cap)
		m = xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapZ32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[zigzag32Item, uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag32Item
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, V](cap)
		m = xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapZ64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[zigzag64Item, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzag64Item
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, V](cap)
		m = xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapF32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[fixed32Item, uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint32, V](cap)
		m = xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU32xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapF64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[fixed64Item, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, V](cap)
		m = xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapSxM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[stringItem, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, V](cap)
		m = xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapBxM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[bytesItem, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint64, V](cap)
		m = xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU64xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMap2xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[boolItem, uint8]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var k uint8
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, V]](p1, p2)

	m := *mp
	if m == nil {
		cap := int(max(1, p2.Field().Preload))
		size, _ := swiss.Layout[uint8, V](cap)
		m = xunsafe.Cast[swiss.Table[uint8, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m)
		swiss.InitU8xP(m, cap, nil, extract)
		xunsafe.StoreNoWB(&m.Scratch, p1.Shared().Src)
	}

	vp := swiss.InsertU8xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, V](m.Len() + 1)
		m2 := xunsafe.Cast[swiss.Table[uint8, V]](p1.Arena().Alloc(size))
		xunsafe.StoreNoWB(mp, m2)
		swiss.InitU8xP(m2, m.Len()+1, m, extract)
		xunsafe.StoreNoWB(&m2.Scratch, p1.Shared().Src)
		vp = swiss.InsertU8xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	xunsafe.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseRepeatedVarint8(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint8]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeated.Scalars[byte, uint8]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint8]](p1, p2)
	p1.Log(p2, "slot", "%v", r.Raw)

	if r.IsZC() {
		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s := slice.Make[uint8](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint8(b))
		}
		s.Store(s.Len()-1, uint8(n))
		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint8](r.Raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint8(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint8(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.Raw = s.Addr().Untyped()
	return p1, p2
}
func parseRepeatedVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint32]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeated.Scalars[byte, uint32]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint32]](p1, p2)
	p1.Log(p2, "slot", "%v", r.Raw)

	if r.IsZC() {
		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s := slice.Make[uint32](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint32(b))
		}
		s.Store(s.Len()-1, uint32(n))
		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint32](r.Raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint32(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint32(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.Raw = s.Addr().Untyped()
	return p1, p2
}
func parseRepeatedVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint64]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeated.Scalars[byte, uint64]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint64]](p1, p2)
	p1.Log(p2, "slot", "%v", r.Raw)

	if r.IsZC() {
		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s := slice.Make[uint64](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint64(b))
		}
		s.Store(s.Len()-1, uint64(n))
		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint64](r.Raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint64(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.Raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint64(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.Raw = s.Addr().Untyped()
	return p1, p2
}

//go:norace // Race instrumentation causes this function to fail the nosplit check.
func parsePackedVarint8(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint8]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var count int
	{
		p := p1.PtrAddr
		e := p1.EndAddr
		e8 := p.Add(layout.RoundDown(int(e-p), 8))
		if p < e8 {
		again:
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & tdp.SignBits)
			p = p.Add(8)
			if p < e8 {
				goto again
			}
		}
		if p < e {
			left := int(e - p)
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & (tdp.SignBits >> uint((8-left)*8)))
		}
	}
	count = n - count

	var r *repeated.Scalars[byte, uint8]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint8]](p1, p2)
	var s slice.Slice[uint8]
	switch {
	case r.Raw.Ptr == 0:
		if count == n {
			r.Raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.Raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.IsZC():

		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s = slice.Make[uint8](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint8(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

	default:
		s = slice.CastUntyped[uint8](r.Raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := xunsafe.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint8(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(xunsafe.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.Raw = s.Addr().Untyped()
	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}

//go:norace // Race instrumentation causes this function to fail the nosplit check.
func parsePackedVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var count int
	{
		p := p1.PtrAddr
		e := p1.EndAddr
		e8 := p.Add(layout.RoundDown(int(e-p), 8))
		if p < e8 {
		again:
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & tdp.SignBits)
			p = p.Add(8)
			if p < e8 {
				goto again
			}
		}
		if p < e {
			left := int(e - p)
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & (tdp.SignBits >> uint((8-left)*8)))
		}
	}
	count = n - count

	var r *repeated.Scalars[byte, uint32]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint32]](p1, p2)
	var s slice.Slice[uint32]
	switch {
	case r.Raw.Ptr == 0:
		if count == n {
			r.Raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.Raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.IsZC():

		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s = slice.Make[uint32](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint32(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

	default:
		s = slice.CastUntyped[uint32](r.Raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := xunsafe.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint32(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(xunsafe.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.Raw = s.Addr().Untyped()
	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}

//go:norace // Race instrumentation causes this function to fail the nosplit check.
func parsePackedVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var count int
	{
		p := p1.PtrAddr
		e := p1.EndAddr
		e8 := p.Add(layout.RoundDown(int(e-p), 8))
		if p < e8 {
		again:
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & tdp.SignBits)
			p = p.Add(8)
			if p < e8 {
				goto again
			}
		}
		if p < e {
			left := int(e - p)
			bytes := *xunsafe.Cast[uint64](p.AssertValid())
			count += bits.OnesCount64(bytes & (tdp.SignBits >> uint((8-left)*8)))
		}
	}
	count = n - count

	var r *repeated.Scalars[byte, uint64]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[byte, uint64]](p1, p2)
	var s slice.Slice[uint64]
	switch {
	case r.Raw.Ptr == 0:
		if count == n {
			r.Raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.Raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.IsZC():

		borrow := slice.CastUntyped[byte](r.Raw).Raw()
		s = slice.Make[uint64](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint64(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())

	default:
		s = slice.CastUntyped[uint64](r.Raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := xunsafe.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint64(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(xunsafe.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.Raw = s.Addr().Untyped()
	p1.EndAddr = xunsafe.Addr[byte](p2.Scratch())
	return p1, p2
}

func appendFixed32(p1 vm.P1, p2 vm.P2, v uint32) (vm.P1, vm.P2) {
	_ = appendFixed[uint32]
	var r *repeated.Scalars[uint32, uint32]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[uint32, uint32]](p1, p2)
	s := slice.CastUntyped[uint32](r.Raw)

	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, v)
		p1.Log(p2, "repeated fixed store", "%v %v", s.Addr(), s)

		r.Raw = s.Addr().Untyped()
		return p1, p2
	} else if r.Raw.OffArena() {

		borrow := s.Raw()
		s = slice.Make[uint32](p1.Arena(), len(borrow)+1)
		copy(s.Raw(), borrow)
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())
	}

	s = s.AppendOne(p1.Arena(), v)
	p1.Log(p2, "repeated fixed append", "%v %v", s.Addr(), s)
	r.Raw = s.Addr().Untyped()
	return p1, p2
}
func appendFixed64(p1 vm.P1, p2 vm.P2, v uint64) (vm.P1, vm.P2) {
	_ = appendFixed[uint64]
	var r *repeated.Scalars[uint64, uint64]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[uint64, uint64]](p1, p2)
	s := slice.CastUntyped[uint64](r.Raw)

	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, v)
		p1.Log(p2, "repeated fixed store", "%v %v", s.Addr(), s)

		r.Raw = s.Addr().Untyped()
		return p1, p2
	} else if r.Raw.OffArena() {

		borrow := s.Raw()
		s = slice.Make[uint64](p1.Arena(), len(borrow)+1)
		copy(s.Raw(), borrow)
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())
	}

	s = s.AppendOne(p1.Arena(), v)
	p1.Log(p2, "repeated fixed append", "%v %v", s.Addr(), s)
	r.Raw = s.Addr().Untyped()
	return p1, p2
}

func parsePackedFixed32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedFixed[uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	size := layout.Size[uint32]()
	if n%size != 0 {
		p1.Fail(p2, vm.ErrorTruncated)
	}

	var r *repeated.Scalars[uint32, uint32]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[uint32, uint32]](p1, p2)

	if r.Raw.Ptr == 0 {

		r.Raw = slice.OffArena(p1.Ptr(), n/size)
		if debug.Enabled {
			p1.Log(p2, "zc", "%v, %v", r.Raw, slice.CastUntyped[uint32](r.Raw))
		}

		p1 = p1.Advance(n)
		goto exit
	}

	{
		s := slice.CastUntyped[uint32](r.Raw)
		if r.Raw.OffArena() {

			borrow := s.Raw()
			s = slice.Make[uint32](p1.Arena(), len(borrow)+n/size)
			copy(s.Raw(), borrow)
			s = s.SetLen(len(borrow))

			p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())
		}

		size := layout.Size[uint32]()
		borrowed := unsafe.Slice(xunsafe.Cast[uint32](p1.Ptr()), n/size)
		if debug.Enabled {
			p1.Log(p2, "appending", "%v, %v", borrowed, s.Raw())
		}

		p1 = p1.Advance(n)

		s = s.Append(p1.Arena(), borrowed...)
		r.Raw = s.Addr().Untyped()
		if debug.Enabled {
			p1.Log(p2, "append", "%v, %v", r.Raw, s.Raw())
		}
	}

exit:
	return p1, p2
}
func parsePackedFixed64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedFixed[uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	size := layout.Size[uint64]()
	if n%size != 0 {
		p1.Fail(p2, vm.ErrorTruncated)
	}

	var r *repeated.Scalars[uint64, uint64]
	p1, p2, r = vm.GetMutableField[repeated.Scalars[uint64, uint64]](p1, p2)

	if r.Raw.Ptr == 0 {

		r.Raw = slice.OffArena(p1.Ptr(), n/size)
		if debug.Enabled {
			p1.Log(p2, "zc", "%v, %v", r.Raw, slice.CastUntyped[uint64](r.Raw))
		}

		p1 = p1.Advance(n)
		goto exit
	}

	{
		s := slice.CastUntyped[uint64](r.Raw)
		if r.Raw.OffArena() {

			borrow := s.Raw()
			s = slice.Make[uint64](p1.Arena(), len(borrow)+n/size)
			copy(s.Raw(), borrow)
			s = s.SetLen(len(borrow))

			p1.Log(p2, "spill", "%v->%v", r.Raw, s.Addr())
		}

		size := layout.Size[uint64]()
		borrowed := unsafe.Slice(xunsafe.Cast[uint64](p1.Ptr()), n/size)
		if debug.Enabled {
			p1.Log(p2, "appending", "%v, %v", borrowed, s.Raw())
		}

		p1 = p1.Advance(n)

		s = s.Append(p1.Arena(), borrowed...)
		r.Raw = s.Addr().Untyped()
		if debug.Enabled {
			p1.Log(p2, "append", "%v, %v", r.Raw, s.Raw())
		}
	}

exit:
	return p1, p2
}
func parseVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseVarint[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))

	var p *uint32
	p1, p2, p = vm.GetMutableField[uint32](p1, p2)
	*p = uint32(p2.Scratch())

	return p1, p2
}
func parseVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseVarint[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))

	var p *uint64
	p1, p2, p = vm.GetMutableField[uint64](p1, p2)
	*p = uint64(p2.Scratch())

	return p1, p2
}

func parseZigZag32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseZigZag[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag.Decode64[uint32](p2.Scratch())))

	var p *uint32
	p1, p2, p = vm.GetMutableField[uint32](p1, p2)
	*p = uint32(p2.Scratch())

	return p1, p2
}
func parseZigZag64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseZigZag[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag.Decode64[uint64](p2.Scratch())))

	var p *uint64
	p1, p2, p = vm.GetMutableField[uint64](p1, p2)
	*p = uint64(p2.Scratch())

	return p1, p2
}

//go:nosplit
func parseFixed32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseFixed[uint32]
	if p1.Len() < layout.Size[uint32]() {
		p1.Fail(p2, vm.ErrorTruncated)
	}
	var p *uint32
	p1, p2, p = vm.GetMutableField[uint32](p1, p2)
	*p = *xunsafe.Cast[uint32](p1.PtrAddr.AssertValid())
	p1 = p1.Advance(layout.Size[uint32]())

	return p1, p2
}

//go:nosplit
func parseFixed64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseFixed[uint64]
	if p1.Len() < layout.Size[uint64]() {
		p1.Fail(p2, vm.ErrorTruncated)
	}
	var p *uint64
	p1, p2, p = vm.GetMutableField[uint64](p1, p2)
	*p = *xunsafe.Cast[uint64](p1.PtrAddr.AssertValid())
	p1 = p1.Advance(layout.Size[uint64]())

	return p1, p2
}
