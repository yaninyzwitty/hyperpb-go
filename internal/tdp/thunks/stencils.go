// Copyright 2025 Buf Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by internal/tools/stencil. DO NOT EDIT.

package thunks

import (
	"github.com/bufbuild/hyperpb/internal/arena/slice"
	"github.com/bufbuild/hyperpb/internal/debug"
	"github.com/bufbuild/hyperpb/internal/swiss"
	"github.com/bufbuild/hyperpb/internal/tdp"
	"github.com/bufbuild/hyperpb/internal/tdp/dynamic"
	"github.com/bufbuild/hyperpb/internal/tdp/vm"
	"github.com/bufbuild/hyperpb/internal/unsafe2"
	"github.com/bufbuild/hyperpb/internal/unsafe2/layout"
	"google.golang.org/protobuf/encoding/protowire"
	"math/bits"
	"unsafe"
)

func parseMapV32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], varintItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], varintItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], zigzagItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], zigzagItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint32], bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], varintItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], varintItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], zigzagItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], zigzagItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapV64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[varintItem[uint64], bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], varintItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], varintItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], zigzagItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], zigzagItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint32], bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], varintItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], varintItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], zigzagItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], zigzagItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapZ64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[zigzagItem[uint64], bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, varintItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, varintItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, zigzagItem[uint32], uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, zigzagItem[uint64], uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, fixed32Item, uint32, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, fixed64Item, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, boolItem, uint32, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, stringItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF32xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed32Item, bytesItem, uint32, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, varintItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, varintItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, zigzagItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, zigzagItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapF64xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[fixed64Item, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, varintItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, varintItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, zigzagItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, zigzagItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSx2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapSxB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[stringItem, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, varintItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, varintItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, zigzagItem[uint32], uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, zigzagItem[uint64], uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, fixed32Item, uint64, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, fixed64Item, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBx2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, boolItem, uint64, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, stringItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMapBxB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[bytesItem, bytesItem, uint64, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xV32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, varintItem[uint32], uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi varintItem[uint32]
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xV64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, varintItem[uint64], uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi varintItem[uint64]
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xZ32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, zigzagItem[uint32], uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi zigzagItem[uint32]
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xZ64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, zigzagItem[uint64], uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi zigzagItem[uint64]
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xF32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, fixed32Item, uint8, uint32]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi fixed32Item
	var k uint8
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint32]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint32]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU32(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xF64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, fixed64Item, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi fixed64Item
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2x2(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, boolItem, uint8, uint8]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi boolItem
	var k uint8
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint8]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint8]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU8(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xS(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, stringItem, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi stringItem
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}
func parseMap2xB(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxV[boolItem, bytesItem, uint8, uint64]

	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var vi bytesItem
	var k uint8
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.Len() == 0 {
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++
			p1, p2, v = vi.parse(p1, p2)
			p1.Log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.PtrAddr, p1.EndAddr,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.PtrAddr == p1.EndAddr {
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, uint64]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, uint64]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xU64(m2, k, extract)
	}

	*vp = v

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}

func parseMapV32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[varintItem[uint32], uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint32]
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, V](1)
		m = unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapV64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[varintItem[uint64], uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki varintItem[uint64]
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, V](1)
		m = unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapZ32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[zigzagItem[uint32], uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint32]
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, V](1)
		m = unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapZ64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[zigzagItem[uint64], uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki zigzagItem[uint64]
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, V](1)
		m = unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapF32xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[fixed32Item, uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed32Item
	var k uint32
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint32, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, V](1)
		m = unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapF64xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[fixed64Item, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki fixed64Item
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, V](1)
		m = unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapSxM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[stringItem, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki stringItem
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, V](1)
		m = unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMapBxM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[bytesItem, uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki bytesItem
	var k uint64
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint64, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, V](1)
		m = unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}
func parseMap2xM(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseMapKxM[boolItem, uint8]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	var ki boolItem
	var k uint8
	var fast bool

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(1, protowire.BytesType)

	if p1.Len() == 0 {
		fast = true
		goto insert
	}
	p1.Log(p2, "first byte", "%#02x", *p1.Ptr())
	if *p1.Ptr() == byte(kTag) {
		p1.PtrAddr++
		p1, p2, k = ki.parse(p1, p2)
		if p1.Len() == 0 {
			fast = true
			goto insert
		}
		p1.Log(p2, "second byte", "%#02x", *p1.Ptr())
		if *p1.Ptr() == byte(vTag) {
			p1.PtrAddr++

			p1, p2, n = p1.LengthPrefix(p2)
			if p1.EndAddr > p1.PtrAddr.Add(n) {
				fast = true
				goto insert
			}
		}
	}

	for p1.PtrAddr < p1.EndAddr {
		var tag uint64
		p1, p2, tag = p1.Varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.Buf())
			if m < 0 {
				p1.Fail(p2, -vm.ErrorCode(m))
			}
			p1.PtrAddr = p1.PtrAddr.Add(m)
		}
	}

	p1.PtrAddr = p1.EndAddr.Add(-n)

insert:
	type V = unsafe.Pointer

	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint8, V]
	p1, p2, mp = vm.GetMutableField[*swiss.Table[uint8, V]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint8, V](1)
		m = unsafe2.Cast[swiss.Table[uint8, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU8xP(m, 1, nil, extract)
	}

	vp := swiss.InsertU8xP(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint8, V](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint8, V]](p1.Arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU8xP(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU8xP(m2, k, extract)
	}

	var v *dynamic.Message

	p1, p2, v = vm.AllocMessage(p1, p2)
	unsafe2.StoreNoWBUntyped(vp, unsafe.Pointer(v))

	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	p1, p2 = p1.SetScratch(p2, uint64(n))

	if fast {
		p1.Log(p2, "fast map entry", "%d", n)
		return p1.PushMessage(p2, v)
	}

	p1.Log(p2, "slow map entry", "%d", n)
	return p1.PushMapEntry(p2, v)
}

//go:nosplit
func parseOneofVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOneofVarint[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)
	unsafe2.ByteStore(p2.Message(), p2.Field().Offset.Bit, p2.Field().Offset.Number)

	return p1, p2
}

//go:nosplit
func parseOneofVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOneofVarint[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)
	unsafe2.ByteStore(p2.Message(), p2.Field().Offset.Bit, p2.Field().Offset.Number)

	return p1, p2
}

//go:nosplit
func parseOneofZigZag32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOneofZigZag[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint32](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)
	unsafe2.ByteStore(p2.Message(), p2.Field().Offset.Bit, p2.Field().Offset.Number)

	return p1, p2
}

//go:nosplit
func parseOneofZigZag64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOneofZigZag[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint64](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)
	unsafe2.ByteStore(p2.Message(), p2.Field().Offset.Bit, p2.Field().Offset.Number)

	return p1, p2
}

//go:nosplit
func parseOptionalVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOptionalVarint[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)
	return vm.SetBit(p1, p2)
}

//go:nosplit
func parseOptionalVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOptionalVarint[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)
	return vm.SetBit(p1, p2)
}

//go:nosplit
func parseOptionalZigZag32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOptionalZigZag[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint32](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)
	return vm.SetBit(p1, p2)
}

//go:nosplit
func parseOptionalZigZag64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseOptionalZigZag[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint64](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)
	return vm.SetBit(p1, p2)
}

//go:nosplit
func parseRepeatedVarint8(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint8]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeatedScalar[byte, uint8]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint8]](p1, p2)
	p1.Log(p2, "slot", "%v", r.raw)

	if r.raw.OffArena() {
		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s := slice.Make[uint8](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint8(b))
		}
		s.Store(s.Len()-1, uint8(n))
		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint8](r.raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint8(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint8(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.raw = s.Addr().Untyped()
	return p1, p2
}

//go:nosplit
func parseRepeatedVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint32]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeatedScalar[byte, uint32]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint32]](p1, p2)
	p1.Log(p2, "slot", "%v", r.raw)

	if r.raw.OffArena() {
		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s := slice.Make[uint32](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint32(b))
		}
		s.Store(s.Len()-1, uint32(n))
		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint32](r.raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint32(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint32(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.raw = s.Addr().Untyped()
	return p1, p2
}

//go:nosplit
func parseRepeatedVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseRepeatedVarint[uint64]
	var n uint64
	p1, p2, n = p1.Varint(p2)

	var r *repeatedScalar[byte, uint64]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint64]](p1, p2)
	p1.Log(p2, "slot", "%v", r.raw)

	if r.raw.OffArena() {
		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s := slice.Make[uint64](p1.Arena(), len(borrow)+1)
		for i, b := range borrow {
			s.Store(i, uint64(b))
		}
		s.Store(s.Len()-1, uint64(n))
		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s := slice.CastUntyped[uint64](r.raw)
	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, uint64(n))

		p1.Log(p2, "store", "%v", s.Addr())
		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), uint64(n))
	p1.Log(p2, "append", "%v", s.Addr())
	r.raw = s.Addr().Untyped()
	return p1, p2
}

//go:nosplit
func parsePackedVarint8(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint8]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.PtrAddr; p < p1.EndAddr; p += 8 {
		n := min(8, p1.EndAddr.Sub(p))
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= tdp.SignBits << uint(n*8)
		count += bits.OnesCount64(tdp.SignBits &^ bytes)
	}

	var r *repeatedScalar[byte, uint8]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint8]](p1, p2)
	var s slice.Slice[uint8]
	switch {
	case r.raw.Ptr == 0:
		if count == n {
			r.raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.raw.OffArena():

		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s = slice.Make[uint8](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint8(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

	default:
		s = slice.CastUntyped[uint8](r.raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := unsafe2.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint8(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(unsafe2.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.raw = s.Addr().Untyped()
	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}

//go:nosplit
func parsePackedVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.PtrAddr; p < p1.EndAddr; p += 8 {
		n := min(8, p1.EndAddr.Sub(p))
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= tdp.SignBits << uint(n*8)
		count += bits.OnesCount64(tdp.SignBits &^ bytes)
	}

	var r *repeatedScalar[byte, uint32]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint32]](p1, p2)
	var s slice.Slice[uint32]
	switch {
	case r.raw.Ptr == 0:
		if count == n {
			r.raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.raw.OffArena():

		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s = slice.Make[uint32](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint32(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

	default:
		s = slice.CastUntyped[uint32](r.raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := unsafe2.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint32(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(unsafe2.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.raw = s.Addr().Untyped()
	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}

//go:nosplit
func parsePackedVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedVarint[uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p1, p2 = p1.SetScratch(p2, uint64(p1.EndAddr))
	p1.EndAddr = p1.PtrAddr.Add(n)

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.PtrAddr; p < p1.EndAddr; p += 8 {
		n := min(8, p1.EndAddr.Sub(p))
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= tdp.SignBits << uint(n*8)
		count += bits.OnesCount64(tdp.SignBits &^ bytes)
	}

	var r *repeatedScalar[byte, uint64]
	p1, p2, r = vm.GetMutableField[repeatedScalar[byte, uint64]](p1, p2)
	var s slice.Slice[uint64]
	switch {
	case r.raw.Ptr == 0:
		if count == n {
			r.raw = slice.OffArena(p1.Ptr(), n)
			p1.Log(p2, "zc", "%v", r.raw)

			p1.PtrAddr = p1.EndAddr
			p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
			return p1, p2
		}
		s = s.Grow(p1.Arena(), count)
		p1.Log(p2, "grow", "%v", s.Addr())

	case r.raw.OffArena():

		borrow := slice.CastUntyped[byte](r.raw).Raw()
		s = slice.Make[uint64](p1.Arena(), len(borrow)+count)
		for i, b := range borrow {
			s.Store(i, uint64(b))
		}
		s = s.SetLen(len(borrow))

		p1.Log(p2, "spill", "%v->%v", r.raw, s.Addr())

	default:
		s = slice.CastUntyped[uint64](r.raw)
		if spare := s.Cap() - s.Len(); spare < count {
			s = s.Grow(p1.Arena(), count-spare)
			p1.Log(p2, "grow", "%v, %d", s.Addr(), spare)
		}
	}

	p := unsafe2.AddrOf(s.Ptr()).Add(s.Len())
	p1.Log(p2, "store at", "%v", p)

	switch {
	case count == p1.Len():
		for {
			*p.AssertValid() = uint64(*p1.Ptr())
			p1.PtrAddr++
			p = p.Add(1)

			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	case count >= p1.Len()/2:
		for {
			var x uint64
			if v := *p1.Ptr(); int8(v) >= 0 {
				x = uint64(v)
				p1.PtrAddr++
			} else if c := p1.PtrAddr.Add(1); c != p1.EndAddr && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.Ptr()&0x7f) | uint64(*c.AssertValid())<<7
				p1.PtrAddr += 2
			} else {
				p1, p2, x = p1.Varint(p2)
			}

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.Varint(p2)

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.PtrAddr != p1.EndAddr {
				continue
			}

			break
		}
	}

	s = s.SetLen(p.Sub(unsafe2.AddrOf(s.Ptr())))
	p1.Log(p2, "append", "%v", s.Addr())

	r.raw = s.Addr().Untyped()
	p1.EndAddr = unsafe2.Addr[byte](p2.Scratch())
	return p1, p2
}

//go:nosplit
func appendFixed32(p1 vm.P1, p2 vm.P2, v uint32) (vm.P1, vm.P2) {
	_ = appendFixed[uint32]
	var r *repeatedScalar[uint32, uint32]
	p1, p2, r = vm.GetMutableField[repeatedScalar[uint32, uint32]](p1, p2)
	s := slice.CastUntyped[uint32](r.raw)

	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, v)
		p1.Log(p2, "repeated fixed store", "%v %v", s.Addr(), s)

		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), v)
	p1.Log(p2, "repeated fixed append", "%v %v", s.Addr(), s)
	r.raw = s.Addr().Untyped()
	return p1, p2
}

//go:nosplit
func appendFixed64(p1 vm.P1, p2 vm.P2, v uint64) (vm.P1, vm.P2) {
	_ = appendFixed[uint64]
	var r *repeatedScalar[uint64, uint64]
	p1, p2, r = vm.GetMutableField[repeatedScalar[uint64, uint64]](p1, p2)
	s := slice.CastUntyped[uint64](r.raw)

	if s.Len() < s.Cap() {
		s = s.SetLen(s.Len() + 1)
		s.Store(s.Len()-1, v)
		p1.Log(p2, "repeated fixed store", "%v %v", s.Addr(), s)

		r.raw = s.Addr().Untyped()
		return p1, p2
	}

	s = s.AppendOne(p1.Arena(), v)
	p1.Log(p2, "repeated fixed append", "%v %v", s.Addr(), s)
	r.raw = s.Addr().Untyped()
	return p1, p2
}

//go:nosplit
func parsePackedFixed32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedFixed[uint32]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	size := layout.Size[uint32]()
	if n%size != 0 {
		p1.Fail(p2, vm.ErrorTruncated)
	}

	var r *repeatedScalar[uint32, uint32]
	p1, p2, r = vm.GetMutableField[repeatedScalar[uint32, uint32]](p1, p2)

	if r.raw.Ptr == 0 {

		r.raw = slice.OffArena(p1.Ptr(), n/size)
		if debug.Enabled {
			p1.Log(p2, "zc", "%v, %v", r.raw, slice.CastUntyped[uint32](r.raw))
		}

		p1 = p1.Advance(n)
		goto exit
	}

	{
		s := slice.CastUntyped[uint32](r.raw)
		size := layout.Size[uint32]()
		borrowed := unsafe2.Slice(unsafe2.Cast[uint32](p1.Ptr()), n/size)
		if debug.Enabled {
			p1.Log(p2, "appending", "%v, %v", borrowed, s.Raw())
		}

		p1 = p1.Advance(n)

		s = s.Append(p1.Arena(), borrowed...)
		r.raw = s.Addr().Untyped()
		if debug.Enabled {
			p1.Log(p2, "append", "%v, %v", r.raw, s.Raw())
		}
	}

exit:
	return p1, p2
}

//go:nosplit
func parsePackedFixed64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parsePackedFixed[uint64]
	var n int
	p1, p2, n = p1.LengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	size := layout.Size[uint64]()
	if n%size != 0 {
		p1.Fail(p2, vm.ErrorTruncated)
	}

	var r *repeatedScalar[uint64, uint64]
	p1, p2, r = vm.GetMutableField[repeatedScalar[uint64, uint64]](p1, p2)

	if r.raw.Ptr == 0 {

		r.raw = slice.OffArena(p1.Ptr(), n/size)
		if debug.Enabled {
			p1.Log(p2, "zc", "%v, %v", r.raw, slice.CastUntyped[uint64](r.raw))
		}

		p1 = p1.Advance(n)
		goto exit
	}

	{
		s := slice.CastUntyped[uint64](r.raw)
		size := layout.Size[uint64]()
		borrowed := unsafe2.Slice(unsafe2.Cast[uint64](p1.Ptr()), n/size)
		if debug.Enabled {
			p1.Log(p2, "appending", "%v, %v", borrowed, s.Raw())
		}

		p1 = p1.Advance(n)

		s = s.Append(p1.Arena(), borrowed...)
		r.raw = s.Addr().Untyped()
		if debug.Enabled {
			p1.Log(p2, "append", "%v, %v", r.raw, s.Raw())
		}
	}

exit:
	return p1, p2
}

//go:nosplit
func parseVarint32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseVarint[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)

	return p1, p2
}

//go:nosplit
func parseVarint64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseVarint[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)

	return p1, p2
}

//go:nosplit
func parseZigZag32(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseZigZag[uint32]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint32](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint32](p1, p2)

	return p1, p2
}

//go:nosplit
func parseZigZag64(p1 vm.P1, p2 vm.P2) (vm.P1, vm.P2) {
	_ = parseZigZag[uint64]
	p1, p2 = vm.P1.SetScratch(p1.Varint(p2))
	p1, p2 = p1.SetScratch(p2, uint64(zigzag64[uint64](p2.Scratch())))
	p1, p2 = vm.StoreFromScratch[uint64](p1, p2)

	return p1, p2
}
