// Copyright 2020-2025 Buf Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package fastpb

// Code generated by internal/stencil. DO NOT EDIT

import (
	"math/bits"

	"github.com/bufbuild/fastpb/internal/arena"
	"github.com/bufbuild/fastpb/internal/unsafe2"
)

//go:nosplit
func parseVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseVarint[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, uint32(n))

	return p1, p2
}

//go:nosplit
func parseVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseVarint[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, uint64(n))

	return p1, p2
}

//go:nosplit
func parseZigZag32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseZigZag[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, zigzag64[uint32](n))

	return p1, p2
}

//go:nosplit
func parseZigZag64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseZigZag[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, zigzag64[uint64](n))

	return p1, p2
}

//go:nosplit
func parseOptionalVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalVarint[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, uint32(n))
	p2.m().setBit(p2.f().offset.bit, true)

	return p1, p2
}

//go:nosplit
func parseOptionalVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalVarint[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, uint64(n))
	p2.m().setBit(p2.f().offset.bit, true)

	return p1, p2
}

//go:nosplit
func parseOptionalZigZag32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalZigZag[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, zigzag64[uint32](n))
	p2.m().setBit(p2.f().offset.bit, true)

	return p1, p2
}

//go:nosplit
func parseOptionalZigZag64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalZigZag[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)
	storeField(p1, p2, zigzag64[uint64](n))
	p2.m().setBit(p2.f().offset.bit, true)

	return p1, p2
}

//go:nosplit
func appendVarint8(p1 parser1, p2 parser2, v uint8) (parser1, parser2) {
	_ = appendVarint[uint8]
	rep := unsafe2.Cast[rep[uint8]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		zc := repCast[byte](*rep).zc(p1.c().src)
		slice := arena.NewSlice[uint8](p1.arena(), len(zc)+1)
		for i, b := range zc {
			unsafe2.Store(slice.Ptr(), i, uint8(b))
		}
		unsafe2.Store(slice.Ptr(), slice.Len(), v)
		rep.setArena(slice)
		return p1, p2
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func appendVarint32(p1 parser1, p2 parser2, v uint32) (parser1, parser2) {
	_ = appendVarint[uint32]
	rep := unsafe2.Cast[rep[uint32]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		zc := repCast[byte](*rep).zc(p1.c().src)
		slice := arena.NewSlice[uint32](p1.arena(), len(zc)+1)
		for i, b := range zc {
			unsafe2.Store(slice.Ptr(), i, uint32(b))
		}
		unsafe2.Store(slice.Ptr(), slice.Len(), v)
		rep.setArena(slice)
		return p1, p2
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func appendVarint64(p1 parser1, p2 parser2, v uint64) (parser1, parser2) {
	_ = appendVarint[uint64]
	rep := unsafe2.Cast[rep[uint64]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		zc := repCast[byte](*rep).zc(p1.c().src)
		slice := arena.NewSlice[uint64](p1.arena(), len(zc)+1)
		for i, b := range zc {
			unsafe2.Store(slice.Ptr(), i, uint64(b))
		}
		unsafe2.Store(slice.Ptr(), slice.Len(), v)
		rep.setArena(slice)
		return p1, p2
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func appendFixed8(p1 parser1, p2 parser2, v uint8) (parser1, parser2) {
	_ = appendFixed[uint8]
	rep := unsafe2.Cast[rep[uint8]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		p1, p2, rep = spillArena8(p1, p2, rep)
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func appendFixed32(p1 parser1, p2 parser2, v uint32) (parser1, parser2) {
	_ = appendFixed[uint32]
	rep := unsafe2.Cast[rep[uint32]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		p1, p2, rep = spillArena32(p1, p2, rep)
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func appendFixed64(p1 parser1, p2 parser2, v uint64) (parser1, parser2) {
	_ = appendFixed[uint64]
	rep := unsafe2.Cast[rep[uint64]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	if rep.isZC() && rep.cap > 0 {

		p1, p2, rep = spillArena64(p1, p2, rep)
	}

	if rep.len < rep.cap {
		unsafe2.Store(rep.ptr.AssertValid(), rep.len, v)
		rep.len++
		return p1, p2
	}

	rep.setArena(rep.arena().AppendOne(p1.arena(), v))
	return p1, p2
}

//go:nosplit
func spillArena8(p1 parser1, p2 parser2, rep *rep[uint8]) (parser1, parser2, *rep[uint8]) {
	_ = spillArena[uint8]
	slice := rep.zc(p1.c().src)
	rep.setArena(arena.SliceOf(p1.arena(), slice...))
	return p1, p2, rep
}

//go:nosplit
func spillArena32(p1 parser1, p2 parser2, rep *rep[uint32]) (parser1, parser2, *rep[uint32]) {
	_ = spillArena[uint32]
	slice := rep.zc(p1.c().src)
	rep.setArena(arena.SliceOf(p1.arena(), slice...))
	return p1, p2, rep
}

//go:nosplit
func spillArena64(p1 parser1, p2 parser2, rep *rep[uint64]) (parser1, parser2, *rep[uint64]) {
	_ = spillArena[uint64]
	slice := rep.zc(p1.c().src)
	rep.setArena(arena.SliceOf(p1.arena(), slice...))
	return p1, p2, rep
}

//go:nosplit
func parseRepeatedVarint8(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint8]
	var n uint64
	p1, p2, n = p1.varint(p2)
	p1, p2 = appendVarint8(p1, p2, uint8(n))

	return p1, p2
}

//go:nosplit
func parseRepeatedVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)
	p1, p2 = appendVarint32(p1, p2, uint32(n))

	return p1, p2
}

//go:nosplit
func parseRepeatedVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)
	p1, p2 = appendVarint64(p1, p2, uint64(n))

	return p1, p2
}

//go:nosplit
func parsePackedVarint8(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint8]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var count uint32
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += uint32(bits.OnesCount64(signBits &^ bytes))
	}

	rep := unsafe2.Cast[rep[uint8]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))
	if rep.isZC() {

		switch {
		case rep.cap > 0:

			zc := repCast[byte](*rep).zc(p1.c().src)
			slice := arena.NewSlice[uint8](p1.arena(), len(zc)+int(count))
			for i, b := range zc {
				unsafe2.Store(slice.Ptr(), i, uint8(b))
			}
			rep.setArena(slice)

		case count == n:
			offset := p1.b_.Sub(unsafe2.AddrOf(p1.c().src))

			rep.setZC(zc{uint32(offset), n})
			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			rep.setArena(rep.arena().Grow(p1.arena(), int(count)))
		}
	} else if spare := rep.cap - rep.len; spare < count {
		rep.setArena(rep.arena().Grow(p1.arena(), int(count-spare)))
	}

	p := rep.ptr.Add(int(rep.len))

	switch {
	case count == uint32(p1.len()):
		for {
			*p.AssertValid() = uint8(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= uint32(p1.len())/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	rep.len = uint32(p.Sub(rep.ptr))
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parsePackedVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint32]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var count uint32
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += uint32(bits.OnesCount64(signBits &^ bytes))
	}

	rep := unsafe2.Cast[rep[uint32]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))
	if rep.isZC() {

		switch {
		case rep.cap > 0:

			zc := repCast[byte](*rep).zc(p1.c().src)
			slice := arena.NewSlice[uint32](p1.arena(), len(zc)+int(count))
			for i, b := range zc {
				unsafe2.Store(slice.Ptr(), i, uint32(b))
			}
			rep.setArena(slice)

		case count == n:
			offset := p1.b_.Sub(unsafe2.AddrOf(p1.c().src))

			rep.setZC(zc{uint32(offset), n})
			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			rep.setArena(rep.arena().Grow(p1.arena(), int(count)))
		}
	} else if spare := rep.cap - rep.len; spare < count {
		rep.setArena(rep.arena().Grow(p1.arena(), int(count-spare)))
	}

	p := rep.ptr.Add(int(rep.len))

	switch {
	case count == uint32(p1.len()):
		for {
			*p.AssertValid() = uint32(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= uint32(p1.len())/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	rep.len = uint32(p.Sub(rep.ptr))
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parsePackedVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint64]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var count uint32
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += uint32(bits.OnesCount64(signBits &^ bytes))
	}

	rep := unsafe2.Cast[rep[uint64]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))
	if rep.isZC() {

		switch {
		case rep.cap > 0:

			zc := repCast[byte](*rep).zc(p1.c().src)
			slice := arena.NewSlice[uint64](p1.arena(), len(zc)+int(count))
			for i, b := range zc {
				unsafe2.Store(slice.Ptr(), i, uint64(b))
			}
			rep.setArena(slice)

		case count == n:
			offset := p1.b_.Sub(unsafe2.AddrOf(p1.c().src))

			rep.setZC(zc{uint32(offset), n})
			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			rep.setArena(rep.arena().Grow(p1.arena(), int(count)))
		}
	} else if spare := rep.cap - rep.len; spare < count {
		rep.setArena(rep.arena().Grow(p1.arena(), int(count-spare)))
	}

	p := rep.ptr.Add(int(rep.len))

	switch {
	case count == uint32(p1.len()):
		for {
			*p.AssertValid() = uint64(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= uint32(p1.len())/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	rep.len = uint32(p.Sub(rep.ptr))
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parsePackedFixed32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedFixed[uint32]
	var zc zc
	p1, p2, zc = p1.bytes(p2)

	size, _ := unsafe2.Layout[uint32]()
	if int(zc.len)%size != 0 {
		p1.fail(p2, errCodeTruncated)
	}

	rep := unsafe2.Cast[rep[uint32]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	switch {
	case !rep.isZC():

	case rep.cap == 0:

		rep.setZC(zc)
		goto exit
	default:

		p1, p2, rep = spillArena(p1, p2, rep)
	}

	{
		size, _ := unsafe2.Layout[uint32]()
		borrowed := unsafe2.Slice(
			unsafe2.Cast[uint32](unsafe2.Add(p1.c().src, zc.offset)),
			int(zc.len)/size,
		)

		slice := rep.arena()
		slice = slice.Append(p1.arena(), borrowed...)
		rep.setArena(slice)
	}

exit:
	return p1, p2
}

//go:nosplit
func parsePackedFixed64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedFixed[uint64]
	var zc zc
	p1, p2, zc = p1.bytes(p2)

	size, _ := unsafe2.Layout[uint64]()
	if int(zc.len)%size != 0 {
		p1.fail(p2, errCodeTruncated)
	}

	rep := unsafe2.Cast[rep[uint64]](unsafe2.ByteAdd(p2.m(), p2.f().offset.data))

	switch {
	case !rep.isZC():

	case rep.cap == 0:

		rep.setZC(zc)
		goto exit
	default:

		p1, p2, rep = spillArena(p1, p2, rep)
	}

	{
		size, _ := unsafe2.Layout[uint64]()
		borrowed := unsafe2.Slice(
			unsafe2.Cast[uint64](unsafe2.Add(p1.c().src, zc.offset)),
			int(zc.len)/size,
		)

		slice := rep.arena()
		slice = slice.Append(p1.arena(), borrowed...)
		rep.setArena(slice)
	}

exit:
	return p1, p2
}
